{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-20T15:33:35.072757Z","iopub.execute_input":"2023-09-20T15:33:35.073125Z","iopub.status.idle":"2023-09-20T15:33:35.430658Z","shell.execute_reply.started":"2023-09-20T15:33:35.073096Z","shell.execute_reply":"2023-09-20T15:33:35.429657Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"IMPORT ALL DEPENDENCIES","metadata":{}},{"cell_type":"code","source":"pip install autocorrect","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:33:35.432566Z","iopub.execute_input":"2023-09-20T15:33:35.433099Z","iopub.status.idle":"2023-09-20T15:33:51.966258Z","shell.execute_reply.started":"2023-09-20T15:33:35.433066Z","shell.execute_reply":"2023-09-20T15:33:51.965077Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting autocorrect\n  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=528147308865c5d5c07b5ff73f6e7a99358d28bece8f9af45e79f251700f0672\n  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\nSuccessfully installed autocorrect-2.6.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:33:51.968129Z","iopub.execute_input":"2023-09-20T15:33:51.968534Z","iopub.status.idle":"2023-09-20T15:34:04.761165Z","shell.execute_reply.started":"2023-09-20T15:33:51.968496Z","shell.execute_reply":"2023-09-20T15:34:04.758710Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pyspellchecker\n  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.7.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport string\nfrom collections import Counter\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc ##garbage collection \n\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error\n\nimport optuna\nimport lightgbm as lgb\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\n\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom torch import nn\nimport torch.optim as optim\nfrom transformers import DataCollatorWithPadding, AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup, Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:04.764723Z","iopub.execute_input":"2023-09-20T15:34:04.765133Z","iopub.status.idle":"2023-09-20T15:34:22.729423Z","shell.execute_reply.started":"2023-09-20T15:34:04.765092Z","shell.execute_reply":"2023-09-20T15:34:22.728392Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"prompts=pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nsummaries=pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\ndf=prompts.merge(summaries,on=['prompt_id'],how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:22.730854Z","iopub.execute_input":"2023-09-20T15:34:22.731827Z","iopub.status.idle":"2023-09-20T15:34:22.850905Z","shell.execute_reply.started":"2023-09-20T15:34:22.731791Z","shell.execute_reply":"2023-09-20T15:34:22.849850Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:22.852424Z","iopub.execute_input":"2023-09-20T15:34:22.852774Z","iopub.status.idle":"2023-09-20T15:34:22.873977Z","shell.execute_reply.started":"2023-09-20T15:34:22.852739Z","shell.execute_reply":"2023-09-20T15:34:22.872624Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n3  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n4  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n\n                                                text   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0086ef22de8f</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n      <td>-0.970237</td>\n      <td>-0.417058</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0094589c7a22</td>\n      <td>Aristotle states that an ideal tragedy should ...</td>\n      <td>-0.387791</td>\n      <td>-0.584181</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00cd5736026a</td>\n      <td>One element of an Ideal tragedy is having a co...</td>\n      <td>0.088882</td>\n      <td>-0.594710</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00d98b8ff756</td>\n      <td>The 3 ideal of tragedy is how complex you need...</td>\n      <td>-0.687288</td>\n      <td>-0.460886</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n#Test\nprompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\nsummaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest = prompts_test.merge(summaries_test, on = ['prompt_id'],how ='left')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:22.875560Z","iopub.execute_input":"2023-09-20T15:34:22.876087Z","iopub.status.idle":"2023-09-20T15:34:22.895041Z","shell.execute_reply.started":"2023-09-20T15:34:22.876049Z","shell.execute_reply":"2023-09-20T15:34:22.894077Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:22.896697Z","iopub.execute_input":"2023-09-20T15:34:22.897088Z","iopub.status.idle":"2023-09-20T15:34:22.911122Z","shell.execute_reply.started":"2023-09-20T15:34:22.897056Z","shell.execute_reply":"2023-09-20T15:34:22.909841Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n\n             text  \n0  Example text 1  \n1  Example text 3  \n2  Example text 2  \n3  Example text 4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>111111eeeeee</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>333333dddddd</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"spell = Speller(lang='en')\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\n', ' ', text)\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndf['prompt_text'] = df['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['prompt_text'] = test['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:34:22.913097Z","iopub.execute_input":"2023-09-20T15:34:22.914091Z","iopub.status.idle":"2023-09-20T15:38:29.666767Z","shell.execute_reply.started":"2023-09-20T15:34:22.914054Z","shell.execute_reply":"2023-09-20T15:38:29.665649Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoModel\nmodel_name=\"microsoft/deberta-v3-base\"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, problem_type=\"regression\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:29.672234Z","iopub.execute_input":"2023-09-20T15:38:29.672662Z","iopub.status.idle":"2023-09-20T15:38:38.311346Z","shell.execute_reply.started":"2023-09-20T15:38:29.672635Z","shell.execute_reply":"2023-09-20T15:38:38.310337Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10d760246a5415b925a040cbe0bf1e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8117bb2c178d42819be455305219702f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f7fc0a2811480faf6fd5d2a90dddc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19eccef7a2e34731ada785d1e5778fd4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, has_labels=True):\n        self.df = df\n        self.prompt_titles = df[\"question\"].values.tolist()\n        self.texts = df[\"correct_text\"].values.tolist()\n        self.encoded_examples = tokenizer(\n            text=self.prompt_titles,\n            text_pair=self.texts,\n            truncation=True,\n            padding=True,\n            max_length=512,\n            return_tensors=\"pt\"\n        )\n        self.has_labels = has_labels\n        \n        if self.has_labels:\n            self.labels_list = df[[\"content\", \"wording\"]].values.tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encoded_examples[\"input_ids\"][idx],\n            \"attention_mask\": self.encoded_examples[\"attention_mask\"][idx],\n            \"token_type_ids\": self.encoded_examples[\"token_type_ids\"][idx]\n        }\n        \n        if self.has_labels:\n            item[\"labels\"] = torch.tensor(self.labels_list[idx])\n        \n        return item","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:38.312688Z","iopub.execute_input":"2023-09-20T15:38:38.313531Z","iopub.status.idle":"2023-09-20T15:38:38.323602Z","shell.execute_reply.started":"2023-09-20T15:38:38.313495Z","shell.execute_reply":"2023-09-20T15:38:38.322373Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:38.326763Z","iopub.execute_input":"2023-09-20T15:38:38.327127Z","iopub.status.idle":"2023-09-20T15:38:39.431520Z","shell.execute_reply.started":"2023-09-20T15:38:38.327101Z","shell.execute_reply":"2023-09-20T15:38:39.430122Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Wed Sep 20 15:38:39 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   40C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_mcrmse(eval_pred):\n\n    predictions, labels = eval_pred\n    squared_errors = np.square(predictions - labels)\n    mean_squared_errors = np.mean(squared_errors, axis=0)\n    \n    rmse = np.sqrt(mean_squared_errors)\n    \n    mcrmse_value = np.mean(rmse)\n    \n    content_rmse = rmse[0]\n    wording_rmse = rmse[1]\n    \n    return {\n        \"mcrmse\": mcrmse_value,\n        \"content_rmse\": content_rmse,\n        \"wording_rmse\": wording_rmse\n    }","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:39.433482Z","iopub.execute_input":"2023-09-20T15:38:39.434149Z","iopub.status.idle":"2023-09-20T15:38:39.443248Z","shell.execute_reply.started":"2023-09-20T15:38:39.434107Z","shell.execute_reply":"2023-09-20T15:38:39.442014Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:39.445057Z","iopub.execute_input":"2023-09-20T15:38:39.445989Z","iopub.status.idle":"2023-09-20T15:38:39.453270Z","shell.execute_reply.started":"2023-09-20T15:38:39.445962Z","shell.execute_reply":"2023-09-20T15:38:39.452264Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndf['question'] = df[\"prompt_title\"] + \"\\n\" + df[\"prompt_question\"] + \"\\n\" + df[\"prompt_text\"]\ntest['question'] = test[\"prompt_title\"] + \"\\n\" + test[\"prompt_question\"] + \"\\n\" + test[\"prompt_text\"]\n\ndf_train, df_valid = train_test_split(df, test_size=0.2, random_state=2023)\n\ntrain_dataset = CustomDataset(df_train)\nvalid_dataset = CustomDataset(df_valid)\ntest_dataset  = CustomDataset(test, has_labels=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:38:39.455025Z","iopub.execute_input":"2023-09-20T15:38:39.455833Z","iopub.status.idle":"2023-09-20T15:39:02.261434Z","shell.execute_reply.started":"2023-09-20T15:38:39.455799Z","shell.execute_reply":"2023-09-20T15:39:02.260284Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:39:02.263178Z","iopub.execute_input":"2023-09-20T15:39:02.263623Z","iopub.status.idle":"2023-09-20T15:39:02.270290Z","shell.execute_reply.started":"2023-09-20T15:39:02.263588Z","shell.execute_reply":"2023-09-20T15:39:02.269120Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_collator","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:39:02.272148Z","iopub.execute_input":"2023-09-20T15:39:02.273416Z","iopub.status.idle":"2023-09-20T15:39:02.283088Z","shell.execute_reply.started":"2023-09-20T15:39:02.273380Z","shell.execute_reply":"2023-09-20T15:39:02.281898Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DataCollatorWithPadding(tokenizer=DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"output\",             \n    per_device_train_batch_size=8,   \n    per_device_eval_batch_size=4,    \n    learning_rate=1e-3,            \n    lr_scheduler_type=\"linear\",      \n    warmup_ratio=0.01,               \n    num_train_epochs=5,              \n    save_strategy=\"epoch\",           \n    logging_strategy=\"epoch\",        \n    evaluation_strategy=\"epoch\",     \n    load_best_model_at_end=True,     \n    metric_for_best_model=\"mcrmse\",           \n    fp16=False,                      \n    report_to='none',\n    save_total_limit=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:39:02.285043Z","iopub.execute_input":"2023-09-20T15:39:02.285652Z","iopub.status.idle":"2023-09-20T15:39:02.298838Z","shell.execute_reply.started":"2023-09-20T15:39:02.285616Z","shell.execute_reply":"2023-09-20T15:39:02.297821Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_mcrmse,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:39:02.300157Z","iopub.execute_input":"2023-09-20T15:39:02.300528Z","iopub.status.idle":"2023-09-20T15:39:07.327313Z","shell.execute_reply.started":"2023-09-20T15:39:02.300484Z","shell.execute_reply":"2023-09-20T15:39:07.326325Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n\ntrainer.save_model(\"best_model\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T15:39:07.328656Z","iopub.execute_input":"2023-09-20T15:39:07.329135Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='354' max='3585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 354/3585 03:49 < 35:02, 1.54 it/s, Epoch 0.49/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}}]}